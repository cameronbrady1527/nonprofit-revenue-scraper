# Nonprofit Data Analysis Platform

A comprehensive Python toolkit for collecting and analyzing nonprofit financial data from ProPublica's Nonprofit Explorer API. Features AI-powered PDF parsing, real-time GUI monitoring, and high-performance async processing to identify organizations with revenue between $250K - $1M.

## Table of Contents

- [Key Features](#key-features)
  - [Dual Processing Architecture](#dual-processing-architecture)
  - [AI-Powered PDF Parsing](#ai-powered-pdf-parsing)
  - [Real-Time GUI Monitoring](#real-time-gui-monitoring)
  - [Advanced Search Strategy](#advanced-search-strategy)
  - [Professional Data Export](#professional-data-export)
- [Quick Start](#quick-start)
  - [Prerequisites](#prerequisites)
  - [Installation](#installation)
  - [Recommended Usage - GUI Monitoring](#recommended-usage---gui-monitoring)
  - [Alternative Usage Options](#alternative-usage-options)
  - [GUI Monitor Preview](#gui-monitor-preview)
- [Enhanced Output](#enhanced-output)
  - [Excel Files with Professional Formatting](#excel-files-with-professional-formatting)
  - [File Naming & Features](#file-naming--features)
  - [Live Summary Statistics](#live-summary-statistics)
- [How It Works](#how-it-works)
  - [Dual Architecture Processing](#dual-architecture-processing)
  - [AI-Powered Data Extraction](#ai-powered-data-extraction)
  - [Advanced Search Strategy](#advanced-search-strategy-1)
  - [Data Processing Pipeline](#data-processing-pipeline)
- [Performance Metrics](#performance-metrics)
  - [Async Scraper (Recommended)](#async-scraper-recommended)
  - [Sync Scraper (Stable)](#sync-scraper-stable)
  - [Expected Results by State Size](#expected-results-by-state-size)
- [Advanced Rate Limiting & Error Handling](#advanced-rate-limiting--error-handling)
  - [Smart Rate Limit Management](#smart-rate-limit-management)
  - [Intelligent Error Recovery](#intelligent-error-recovery)
  - [Data Quality Assurance](#data-quality-assurance)
- [Enhanced Project Structure](#enhanced-project-structure)
- [Enhanced Sample Output](#enhanced-sample-output)
  - [Real-Time Processing Log](#real-time-processing-log)
  - [Enhanced Final Summary](#enhanced-final-summary)
- [Advanced Troubleshooting](#advanced-troubleshooting)
  - [Setup Issues](#setup-issues)
  - [Runtime Issues](#runtime-issues)
  - [Data Quality Issues](#data-quality-issues)
- [Contributing](#contributing)
  - [High-Impact Improvements](#high-impact-improvements)
  - [Technical Improvements](#technical-improvements)
  - [Development Setup](#development-setup)
- [Enhanced Data Sources](#enhanced-data-sources)
- [Legal & Ethical Use](#legal--ethical-use)
- [Roadmap & Future Enhancements](#roadmap--future-enhancements)
  - [Recently Completed](#recently-completed)
  - [Coming Soon](#coming-soon)
- [License](#license)
- [Acknowledgments](#acknowledgments)
- [Support](#support)

## Key Features

### **Dual Processing Architecture**
- **Async Scraper**: 5-10x faster with concurrent processing (10 API + 3 PDF simultaneous)
- **Sync Scraper**: Stable original version for conservative processing
- **Smart Deduplication**: Real-time EIN tracking prevents duplicate processing

### **AI-Powered PDF Parsing**
- **Gemini 2.5 Flash**: Primary AI-based Form 990 analysis with structured JSON output
- **OCR Fallback**: Legacy `pdfplumber` + `pytesseract` for when AI fails
- **Intelligent Error Recovery**: Automatic fallback between parsing methods
- **Rate Limit Detection**: Distinguishes API limits from legitimate no-data cases

### **Real-Time GUI Monitoring**
- **Three-Panel Dashboard**: Progress tracking, detailed statistics, and live logs
- **Color-Coded Error Tracking**: API ‚úÖ, AI ‚úÖ, Rate Limits ‚ö†Ô∏è, Errors ‚ùå, N/A ‚ÑπÔ∏è
- **Live Performance Metrics**: Success rates, processing speed, data source breakdown
- **Responsive Updates**: Real-time progress and error visibility

### **Advanced Search Strategy**
- **138 Total Search Queries**: Comprehensive coverage beyond API limits
- **41 Nonprofit Terms**: foundation, association, charity, hospital, etc.
- **95 Alphabetical Searches**: Strategic letter combinations for maximum coverage
- **State-Specific Terms**: Includes state names and major cities

### **Professional Data Export**
- **Rich Excel Output**: Auto-formatted columns, revenue sorting, summary statistics
- **Data Source Tracking**: Clear indicators of API vs AI vs N/A data sources
- **Comprehensive Columns**: Name, EIN, Filing Year, Revenue, Compensation + analytics
- **Summary Insights**: Revenue/compensation ranges and data quality metrics

## Quick Start

### Prerequisites

- **Python 3.7+** (Python 3.9+ recommended for best async performance)
- **Internet connection** for API access
- **Google AI API Key** (optional, for Gemini AI parsing - get from [ai.google.dev](https://ai.google.dev))

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/cameronbrady1527/nonprofit-revenue-scraper.git
   cd nonprofit-scraper
   ```

2. **Create a virtual environment**
   ```bash
   # Windows
   python -m venv venv
   venv\Scripts\activate
   
   # Mac/Linux
   python3 -m venv venv
   source venv/bin/activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Set up AI parsing (optional but recommended)**
   ```bash
   # Create .env file with your Gemini API key
   echo "GOOGLE_AI_API_KEY=your_api_key_here" > .env
   ```

### **Recommended Usage** - GUI Monitoring

Launch with real-time monitoring dashboard:

```bash
python launch_with_monitor.py
```

**What you'll see:**
1. üñ•Ô∏è **GUI monitoring window opens** with three-panel dashboard
2. üìã **Interactive setup** - choose async/sync, Gemini/OCR, and state
3. üöÄ **Real-time progress** with live stats, error tracking, and colored logs

### Alternative Usage Options

```bash
# Interactive launcher (choose sync/async + settings)
python scraper_launcher.py

# Original sync scraper directly
python nonprofit_data_scraper.py

# High-performance async scraper directly
python async_nonprofit_scraper.py

# Monitor only (if running scraper separately)
python scraper_monitor.py
```

### **GUI Monitor Preview**

```
‚îå‚îÄ Progress & Summary ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ Detailed Statistics ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë 85.2%   ‚îÇ ‚úÖ Data Sources:          
‚îÇ 1,247 / 1,463 orgs          ‚îÇ   üî¢ API: 892             
‚îÇ State: California (CA)      ‚îÇ   ü§ñ AI: 283              
‚îÇ Method: GEMINI              ‚îÇ ‚ö†Ô∏è Issues:                
‚îÇ Current: Processing orgs    ‚îÇ   üö´ Rate Limits: 12      
‚îÇ Elapsed: 02:34:17           ‚îÇ   ‚ùå Errors: 8            
‚îÇ Avg: 2.3s per org           ‚îÇ   ‚ÑπÔ∏è N/A: 72              
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ üìú Live Logs                                            
‚îÇ [14:23:45] INFO: Processing batch 63/74 (20 orgs)        
‚îÇ [14:23:47] SUCCESS: Found revenue data via API           
‚îÇ [14:23:48] WARNING: Gemini rate limit hit - retrying     
‚îÇ [14:23:51] INFO: OCR fallback successful                 
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Enhanced Output

### Excel Files with Professional Formatting

| Column | Description | Data Source |
|--------|-------------|-------------|
| Organization Name | Legal name of the nonprofit | ProPublica API |
| EIN | Employer Identification Number | ProPublica API |
| Filing Year | Most recent tax filing year | ProPublica API |
| Total Revenue | Revenue amount (e.g., $500,000) | **API** üî¢ or **AI** ü§ñ |
| Executive Compensation | Total compensation if available | **API** üî¢ or **AI** ü§ñ |
| Revenue_Numeric | Raw numbers for analysis | Computed |
| Compensation_Numeric | Raw numbers for analysis | Computed |

### File Naming & Features
- **Async**: `nonprofit_data_ASYNC_California_gemini_20250122_143022.xlsx`
- **Sync**: `nonprofit_data_California_ocr_20250122_143022.xlsx`
- **Auto-sized columns**, **revenue sorting**, **summary statistics**
- **Data quality indicators**: Shows % API vs AI vs N/A data sources

### Live Summary Statistics
```
‚úÖ Results saved to: output/nonprofit_data_ASYNC_CA_gemini_20250122_143022.xlsx
üìä Total organizations saved: 1,247
üí∞ Revenue range: $250,012 - $999,987
üë• Compensation range: $45,000 - $275,000
üéØ Final stats: API: 892 | AI: 283 | N/A: 72 | Rate Limits: 0 | Errors: 0
```

## How It Works

### **Dual Architecture Processing**

#### Async Scraper (Recommended)
- **Concurrent Processing**: 10 simultaneous API calls + 3 PDF parsing processes
- **Performance**: 5-10x faster than sync version
- **Smart Semaphores**: Prevents overwhelming APIs while maximizing throughput
- **Real-time Monitoring**: GUI updates every 3 processed organizations

#### Sync Scraper (Stable)
- **Sequential Processing**: One operation at a time with rate limiting
- **Proven Reliability**: Original stable version with comprehensive logging
- **Conservative Approach**: 0.3-1 second delays between requests

### **AI-Powered Data Extraction**

#### Intelligent PDF Parsing Pipeline
1. **ProPublica API First**: Check if revenue/compensation already available
2. **PDF Download**: Secure download with session warming and header rotation
3. **Gemini AI Analysis**: Send PDF to Gemini 2.5 Flash for structured extraction
4. **OCR Fallback**: If AI fails, use `pdfplumber` + `pytesseract` OCR
5. **Error Categorization**: Distinguish rate limits vs parse failures vs no-data

#### Smart Error Recovery
- **Rate Limit Detection**: Identifies Gemini API quota issues specifically
- **Automatic Fallback**: Seamlessly switches from AI to OCR when needed
- **Retry Logic**: Exponential backoff for temporary failures
- **Graceful Degradation**: Continues processing even when some methods fail

### **Advanced Search Strategy**
Comprehensive approach to overcome ProPublica's 10,000 result API limit:

1. **41 Nonprofit Keywords**: foundation, association, charity, hospital, church, etc.
2. **State-Specific Terms**: State name + abbreviation for targeted results  
3. **95 Alphabetical Searches**: Single letters + strategic two-letter combinations
4. **Real-time Deduplication**: EIN tracking prevents processing duplicates
5. **Total Coverage**: ~138 unique search queries per state = maximum org discovery

### **Data Processing Pipeline**
1. **EIN Collection**: Gather all unique organization IDs across search strategies
2. **Batch Processing**: Process organizations in groups of 20 for optimal performance
3. **Smart Filtering**: Revenue range $250K-$1M with multiple data source attempts
4. **Quality Tracking**: Monitor success rates and error categories in real-time
5. **Professional Export**: Generate formatted Excel with analysis-ready columns

## Performance Metrics

### **Async Scraper (Recommended)**
- **Runtime**: 30 minutes - 2 hours (5-10x faster than sync)
- **Throughput**: 10 concurrent API calls + 3 concurrent PDF processes
- **Large States**: California, Texas, New York - 1-2 hours
- **Small States**: Wyoming, Vermont, Delaware - 15-30 minutes
- **Memory Usage**: Efficient async processing with semaphore controls

### **Sync Scraper (Stable)**
- **Runtime**: 2-8 hours depending on state size
- **Throughput**: Sequential processing with 0.3-1 second delays
- **Memory Usage**: Minimal - processes data incrementally
- **Best For**: Conservative processing, debugging, smaller datasets

### **Expected Results by State Size**
- **Large States** (CA, TX, NY, FL): 800-2,000 qualifying nonprofits
- **Medium States** (OH, PA, IL, MI): 400-800 qualifying nonprofits  
- **Small States** (WY, VT, DE, ND): 50-200 qualifying nonprofits
- **Success Rate**: 70-85% data retrieval (API + AI combined)
- **AI Enhancement**: +15-25% more data vs OCR-only approach

## Advanced Rate Limiting & Error Handling

### **Smart Rate Limit Management**
- **Gemini API**: Automatic rate limit detection with exponential backoff retry
- **ProPublica API**: Respectful delays (0.3-1s sync, semaphore-controlled async)
- **PDF Downloads**: Session warming and header rotation to prevent 403 errors
- **Error Categorization**: Distinguishes rate limits from legitimate no-data cases

### **Intelligent Error Recovery**
- **Automatic Fallback**: Gemini AI ‚Üí OCR ‚Üí Mark as N/A (graceful degradation)
- **Retry Logic**: Exponential backoff for temporary network/API issues  
- **Partial Save**: Graceful interruption with Ctrl+C saves all collected data
- **Real-time Monitoring**: GUI shows exactly where/why errors occur

### **Data Quality Assurance**
- **Duplicate Prevention**: Real-time EIN tracking across all search strategies
- **Revenue Validation**: Filters organizations within $250K-$1M range
- **Data Source Tracking**: Clear indicators of API vs AI vs N/A sources
- **Success Rate Monitoring**: Live tracking of data retrieval effectiveness

## Enhanced Project Structure

```
nonprofit-data-platform/
‚îú‚îÄ‚îÄ üöÄ MAIN LAUNCHERS
‚îÇ   ‚îú‚îÄ‚îÄ launch_with_monitor.py    # üéØ RECOMMENDED: GUI + scraper
‚îÇ   ‚îî‚îÄ‚îÄ scraper_launcher.py       # Interactive launcher
‚îú‚îÄ‚îÄ üîß CORE SCRAPERS  
‚îÇ   ‚îú‚îÄ‚îÄ async_nonprofit_scraper.py # High-performance async scraper
‚îÇ   ‚îú‚îÄ‚îÄ nonprofit_data_scraper.py  # Original stable sync scraper
‚îÇ   ‚îî‚îÄ‚îÄ simple_990_scraper.py      # Simplified version
‚îú‚îÄ‚îÄ ü§ñ AI & PARSING
‚îÇ   ‚îú‚îÄ‚îÄ gemini_pdf_parser.py       # Gemini AI PDF analysis
‚îÇ   ‚îî‚îÄ‚îÄ form_990_parser.py         # Legacy OCR parsing
‚îú‚îÄ‚îÄ üñ•Ô∏è MONITORING
‚îÇ   ‚îú‚îÄ‚îÄ scraper_monitor.py         # Real-time GUI dashboard
‚îÇ   ‚îî‚îÄ‚îÄ MONITOR_README.md          # GUI documentation
‚îú‚îÄ‚îÄ üìã CONFIGURATION
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt           # Dependencies
‚îÇ   ‚îú‚îÄ‚îÄ .env                       # API keys (create this)
‚îÇ   ‚îú‚îÄ‚îÄ CLAUDE.md                  # Developer documentation
‚îÇ   ‚îî‚îÄ‚îÄ README.md                  # This file
‚îî‚îÄ‚îÄ üìä OUTPUT
    ‚îî‚îÄ‚îÄ output/                    # Generated Excel files
```

## Enhanced Sample Output

### **Real-Time Processing Log**
```
üî• Starting ASYNC scraper...
State: California (CA)
Method: GEMINI
Concurrency: 10 API calls, 3 PDF processes
Search Queries: ~138 total (41 nonprofit terms + 2 state terms + 95 alphabetical)
‚ö° This should be much faster than the sync version!

üîç Collecting EINs for 138 search terms...
üìä Total unique organizations found: 15,642 (deduplication handled incrementally)

üöÄ Progress: 1,247/15,642 (8.0%) | API: 892 | AI: 283 | N/A: 72 | Rate Limits: 0 | Errors: 0
```

### **Enhanced Final Summary**
```
=== CALIFORNIA ASYNC SCRAPER RESULTS ===
‚è±Ô∏è  Total processing time: 94.2 minutes
üìà Average: 2.3 seconds per organization  
üéØ Final stats: API: 2,847 | AI: 1,203 | N/A: 892 | Rate Limits: 12 | Errors: 8

‚úÖ Results saved to: output/nonprofit_data_ASYNC_California_gemini_20250122_143022.xlsx
üìä Total organizations saved: 4,050
üí∞ Revenue range: $250,003 - $999,998  
üë• Compensation range: $35,000 - $485,000

üìà SUCCESS METRICS:
  üî¢ API Data: 70.3% (2,847 orgs) - ProPublica had revenue/compensation
  ü§ñ AI Extracted: 29.7% (1,203 orgs) - Gemini successfully parsed PDFs  
  ‚ÑπÔ∏è No Data: 22.0% (892 orgs) - Legitimate cases with no available data
  ‚ö†Ô∏è Issues: 0.5% (20 orgs) - Rate limits + errors (fixable)
```

## Advanced Troubleshooting

### **Setup Issues**

**Missing Dependencies**
```bash
# Ensure virtual environment is activated
source venv/bin/activate  # Mac/Linux
venv\Scripts\activate     # Windows

# Reinstall all dependencies
pip install -r requirements.txt

# For GUI issues on Linux
sudo apt-get install python3-tk
```

**Gemini API Issues**
```bash
# Check if API key is set
echo $GOOGLE_AI_API_KEY  # Mac/Linux
echo %GOOGLE_AI_API_KEY%  # Windows

# Create .env file if missing
echo "GOOGLE_AI_API_KEY=your_key_here" > .env
```

### **Runtime Issues**

**High Rate Limits in GUI**
- Reduce concurrency: Edit `max_concurrent_api=5` and `max_concurrent_pdf=2`
- Switch to sync scraper for conservative processing
- The system automatically falls back to OCR when Gemini hits limits

**GUI Not Responding**
- Close and restart: `python launch_with_monitor.py`
- Run scraper separately: `python async_nonprofit_scraper.py`
- Check Windows firewall/antivirus blocking tkinter

**Poor Success Rates**
- **Expected**: 70-85% overall success rate (API + AI combined)
- **High N/A**: Normal for smaller states or specialized nonprofit types
- **High Errors**: Check internet connection, try sync scraper

### **Data Quality Issues**

**Unexpected Results**
- **Low Revenue Orgs**: Some may have unreported revenue (marked as N/A)
- **Missing Compensation**: Many nonprofits don't report executive compensation
- **Duplicate EINs**: Impossible - real-time deduplication prevents this

**Performance Issues**
- **Slow Processing**: Use async scraper with GUI monitoring
- **Memory Usage**: Async scraper is more memory efficient
- **Network Timeouts**: Built-in retry logic handles temporary issues

## Contributing

Contributions welcome! Priority areas for enhancement:

### **High-Impact Improvements**
- **Enhanced AI Parsing**: Improve Gemini prompts for better financial data extraction
- **Additional Search Terms**: Discover new nonprofit keywords for better coverage
- **Performance Optimization**: Further async improvements and caching strategies
- **Data Validation**: Enhanced verification of extracted financial data
- **Visualization Tools**: Charts and graphs for analysis of collected data

### **Technical Improvements**
- **Database Integration**: PostgreSQL/SQLite storage options
- **Multi-Year Analysis**: Historical trend tracking across filing years
- **Geographic Analysis**: Mapping and regional comparison tools
- **Export Formats**: JSON, CSV, database exports
- **Web Interface**: Browser-based GUI for easier use

### **Development Setup**
1. Fork the repository
2. Create feature branch: `git checkout -b feature-name`
3. Set up development environment with all dependencies
4. Test with both sync and async scrapers
5. Verify GUI monitoring works correctly
6. Submit pull request with comprehensive description

## Enhanced Data Sources

- **ProPublica Nonprofit Explorer API**: Primary organization and filing data
- **IRS Form 990 Data**: Tax filings from 2012-present (1.8+ million filings)
- **Google Gemini AI**: Advanced PDF analysis for financial data extraction
- **Real-time Error Tracking**: Comprehensive categorization of data quality issues
- **Multi-Source Validation**: API data verified against PDF analysis when available

## Legal & Ethical Use

- **Public Data**: All data sourced from public IRS filings via ProPublica's API
- **API Compliance**: Respectful rate limiting and terms of service adherence  
- **AI Ethics**: Gemini AI used only for legitimate financial data extraction
- **Privacy Conscious**: No collection of donor information or private data
- **Intended Use**: Research, journalism, grant-making, and nonprofit sector analysis

## Roadmap & Future Enhancements

### **Recently Completed**
- [x] AI-powered PDF parsing with Gemini 2.5 Flash
- [x] Real-time GUI monitoring dashboard
- [x] High-performance async architecture
- [x] Advanced error categorization and rate limit detection
- [x] Comprehensive search strategy (138 queries per state)

### **Coming Soon**
- [ ] **Multi-Year Trend Analysis**: Track financial changes over time
- [ ] **Advanced Data Visualization**: Interactive charts and geographic mapping
- [ ] **Board Member Data**: Extract key personnel information from filings
- [ ] **Sector Analysis Tools**: Industry-specific nonprofit categorization
- [ ] **Automated Report Generation**: Executive summaries and insights
- [ ] **Database Storage**: PostgreSQL integration for large-scale analysis
- [ ] **Web Interface**: Browser-based tool for non-technical users
- [ ] **API Service**: RESTful API for integration with other tools

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Acknowledgments

- **ProPublica** for providing the Nonprofit Explorer API
- **IRS** for making nonprofit tax data publicly available
- **Python community** for the excellent libraries used in this project

## Support

If you encounter issues or have questions:

1. Check the [Issues](https://github.com/cameronbrady1527/nonprofit-revenue-scraper/issues) page
2. Search existing issues for solutions
3. Create a new issue with detailed information about your problem
4. Include your Python version, operating system, and error messages

---

**‚≠ê If this tool helps your research or work, please consider giving it a star!**

![Python](https://img.shields.io/badge/python-3.7+-blue.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)
![Status](https://img.shields.io/badge/status-active-brightgreen.svg)